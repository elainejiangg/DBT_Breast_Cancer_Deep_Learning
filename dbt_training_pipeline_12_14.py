# -*- coding: utf-8 -*-
"""DBT Training Pipeline 12 14.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/118SuwCfMmhzWXdZU0gtBS8RHoMLHbzer
"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import torchvision
import os
import numpy as np
from PIL import Image
!pip install pydicom

import os

# %matplotlib inline
import matplotlib.pyplot as plt

!cp /content/drive/MyDrive/DBT/duke_dbt_data.py .
!cp /content/drive/MyDrive/DBT/engine.py .
!cp /content/drive/MyDrive/DBT/coco_utils.py .
!cp /content/drive/MyDrive/DBT/coco_eval.py .
!cp /content/drive/MyDrive/DBT/utils.py .
!cp /content/drive/MyDrive/DBT/transforms.py .

from duke_dbt_data import dcmread_image, read_boxes, draw_box, evaluate
import utils
from engine import train_one_epoch, evaluate

from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

!pip install pillow


import torchvision.transforms as TT
import transforms as T

#training data paths

train_imgs_path = "/content/drive/MyDrive/DBT/lesionImages"
train_labels_path = "/content/drive/MyDrive/DBT/BCS-DBT labels-train-v2.csv"
train_boxes_path = "/content/drive/MyDrive/DBT/BCS-DBT boxes-train-v2.csv"
train_fps_path = "/content/drive/MyDrive/DBT/BCS-DBT file-paths-train-v2.csv"

df = read_boxes(boxes_fp=train_boxes_path, filepaths_fp=train_fps_path)

class DBT(torch.utils.data.Dataset):
    def __init__(self, file_dir, transforms, df):
        #root should image folder path
        self.file_dir = file_dir
        self.transforms = transforms
        self.df = df
        self.classes = [_, "lesion"]
        self.imgs = df["descriptive_path"].tolist()
        #volumes have diff views, each bbox on diff view even if same volume

    def __getitem__(self, idx):
        img_path = os.path.join(self.file_dir, self.imgs[idx])
        img_df = df.iloc[idx]
        view = img_df["View"]
        slice_idx = img_df["Slice"]
        image = dcmread_image(fp = img_path, view = view, index = slice_idx)
        norm_image = np.uint8((np.maximum(image,0) / np.max(image)) * 255.0)
        image = Image.fromarray(norm_image)
        #returns PIL.Image.Image
        #int8?

        #may change to just lesions, Check article
        # classes = {
        #     "benign": 1,
        #     "cancer": 2
        # }

        labels = []
        label = 1
        boxes = []
        xmin = img_df["X"]
        ymin = img_df["Y"]
        xmax = xmin + img_df["Width"]
        ymax = ymin + img_df["Height"]
        boxes.append([xmin, ymin, xmax, ymax])
        labels.append(label)

        boxes = torch.as_tensor(boxes, dtype = torch.int64)
        labels = torch.as_tensor(labels, dtype=torch.int64)
        # It should be unique between all the images in the dataset, and is used during evaluation
        image_id = torch.tensor([idx])
        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])
        iscrowd = torch.zeros((1,), dtype = torch.int64) #assuming there is only 1 bbox on each image

        target = {}
        target["boxes"] = boxes
        target["labels"] = labels
        target["image_id"] = image_id
        target["area"] = area
        target["iscrowd"] = iscrowd

        if self.transforms is not None:
            image, target = self.transforms(image, target)

        return image, target

    def __len__(self):
        return len(self.imgs)

def get_transforms(train):
    transforms = []
    transforms.append(T.PILToTensor())
    transforms.append(T.ConvertImageDtype(torch.float))
    # transforms.append(T.Resize(100)) #change to scaling
    # should I normalize??
#     if train:

    #!!!!!!!!!should prob downsize images (have to do same to annotations)
    return T.Compose(transforms)

from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights

def get_faster_rcnn_v2_model(num_classes, pretrain):

    # load a model pre-trained pre-trained on COCO
    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)

    # get number of input features for the classifier
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    # replace the pre-trained head with a new one
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

    return model

#RERUN THIS IF CHANGE DATASET SIZE
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

num_classes = 2
#bkgd, lesion

dataset = DBT(train_imgs_path, get_transforms(train = True), df)
dataset_test = DBT(train_imgs_path, get_transforms(train = False), df)

sample_percent = 1
sample_size = int(sample_percent*len(dataset))
indices = torch.randperm(sample_size).tolist()
train_split = 0.8
train_num = int((train_split*sample_size))
dataset = torch.utils.data.Subset(dataset, indices[:train_num])
dataset_test = torch.utils.data.Subset(dataset_test, indices[train_num:])

data_loader = torch.utils.data.DataLoader(
    dataset, batch_size = 2, shuffle = True, num_workers = 4,
    collate_fn = utils.collate_fn #what does this do?
)

data_loader_test = torch.utils.data.DataLoader(
    dataset_test, batch_size = 4, shuffle = False, num_workers = 4,
    collate_fn = utils.collate_fn
)

# get the model using our helper function
model = get_faster_rcnn_v2_model(num_classes, True)

# move model to the right device
model.to(device)

train_num

import torch
from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter() #not going to use tensorboard

def inference_transforms(image):
  norm_image = np.uint8((np.maximum(image,0) / np.max(image))*255)
  image = Image.fromarray(norm_image)

  testT = torchvision.transforms.Compose([
    torchvision.transforms.PILToTensor(),
    torchvision.transforms.ConvertImageDtype(torch.float),
  ])
  return testT(image)

def predict_slice(slice_idx, image_vol):
  image_slice = image_vol[slice_idx, :, :]

  t_image = inference_transforms(image_slice)

  with torch.no_grad():
    predictions = model([t_image.to(device)])

  return predictions

def NMS_volume(vol_predictions, start_slice, iou_thres, confidence_thres):
  boxes_list = [img_slice[0]["boxes"].to("cpu") for img_slice in vol_predictions]
  scores_list = [img_slice[0]["scores"].to("cpu") for img_slice in vol_predictions]

  boxes_list = torch.cat(boxes_list)
  scores_list = torch.cat(scores_list)

  slice_num_list = []
  for img_slice in vol_predictions:
    for bbox in img_slice[0]["boxes"].tolist():
      slice_num_list.append(start_slice)
    start_slice +=1
  #list of what slice num each bbox is at, correlated w/ idxing

  idxs = torchvision.ops.nms(boxes_list, scores_list, iou_threshold = iou_thres)
  #need to threshold for confidence!!
  keep_idxs = []

  for idx in idxs:
    if scores_list[idx] > confidence_thres:
      keep_idxs.append(idx)

  if len(keep_idxs) > 10:
    keep_idxs = keep_idxs[:10]

  nms_boxes = [boxes_list[idx].tolist() for idx in keep_idxs]
  nms_scores = [scores_list[idx].tolist() for idx in keep_idxs]
  nms_slices = [slice_num_list[idx] for idx in keep_idxs]

  return nms_boxes, nms_scores, nms_slices

import csv

##RERUN THIS IF CHANGE DATALOADER
test_idxs = indices[train_num:]
testing_df = df.iloc[test_idxs]

main_predictions_path = "/content/drive/MyDrive/DBT/predictions45k.csv"
history_predictions_path = "/content/drive/MyDrive/DBT/predictions45khistory.csv"

with open(main_predictions_path, 'w+', newline='') as file:
  writer = csv.writer(file)
  writer.writerow(['PatientID','StudyUID','View','X','Width','Y','Height','Z','Depth','Score'])

def write_csv(predictions_path, PatientID, StudyUID, view, x, width, y, height, Z, depth, score):
  with open(predictions_path, 'a+', newline='') as file:
      writer = csv.writer(file)
      # print(PatientID, StudyUID, view, x, width, y, height, Z, depth, score)
      writer.writerow([PatientID, StudyUID, view, int(x), int(width), int(y), int(height), int(Z), int(depth), score])

#hyperparameters
start_slice = 5
nms_min_iou = 0.5
confidence_thres = 0.1

with open(history_predictions_path, 'w+', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['PatientID','StudyUID','View','X','Width','Y','Height','Z','Depth','Score'])

def test_evaluate():
  #clear evaluation path
  f = open(main_predictions_path, "w+")
  f.close()

  with open(main_predictions_path, 'w+', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['PatientID','StudyUID','View','X','Width','Y','Height','Z','Depth','Score'])

  for index,view_series in testing_df.iterrows():
      view = view_series["View"]
      # if you have image data saved in classic path folder structure, read the file path from "classic_path"
      # image_path = os.path.join("/data", view_series["classic_path"])
      image_path = os.path.join(train_imgs_path, view_series["descriptive_path"])
      PatientID = view_series["PatientID"]
      StudyUID = view_series["StudyUID"]
      VolumeSlices = view_series["VolumeSlices"]

      image_vol = dcmread_image(fp=image_path, view=view)

      vol_predictions = []

      for slice_idx in range(start_slice, VolumeSlices-start_slice):
        slice_prediction = predict_slice(slice_idx, image_vol)
        vol_predictions.append(slice_prediction)

      nms_boxes, nms_scores, nms_slices = NMS_volume(vol_predictions, start_slice, nms_min_iou, confidence_thres)

      num_pred = len(nms_boxes)
      for i in range(num_pred):
        x = int(nms_boxes[i][0])
        width = int(nms_boxes[i][2] - nms_boxes[i][0])
        y = int(nms_boxes[i][1])
        height = int(nms_boxes[i][3] - nms_boxes[i][1])
        Z = int(nms_slices[i])
        depth = 0 #doesn't matter for metrics; Depth is used with Z (first Z coord of bbox) to find the central predicted slice (Z + depth/2).

        write_csv(main_predictions_path, PatientID, StudyUID, view, x, width, y, height, Z, depth, nms_scores[i])
        write_csv(history_predictions_path, PatientID, StudyUID, view, x, width, y, height, Z, depth, nms_scores[i])

  evaluation = evaluate_predictions(train_labels_path, train_boxes_path, main_predictions_path)
  print(evaluation)

from duke_dbt_data import evaluate as evaluate_predictions

from tqdm import tqdm

# construct an optimizer
params = [p for p in model.parameters() if p.requires_grad]
optimizer = torch.optim.SGD(params, lr=0.0005,
                            momentum=0.9, weight_decay=0.0001)
# and a learning rate scheduler
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,
                                                step_size=5,
                                                gamma=0.1)

# let's train it for 10 epochs

num_epochs = 50
#if batch size = 2, about 179 imgs in training set, about 90 iteration/epoch,
#about 4500 total iterations

for epoch in range(num_epochs):
    # train fobr one epoch, printing every 10 iterations
    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)
    # update the learning rate
    lr_scheduler.step()
    # evaluate on the test dataset

    if (epoch % 5 == 0):
      model.eval()
      test_evaluate()

print("Finished Training!")

